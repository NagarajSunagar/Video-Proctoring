{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsKlz6tEkjB9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/AI_Proctoring/Datasets/haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/AI_Proctoring/Datasets/haarcascade_eye.xml')"
      ],
      "metadata": {
        "id": "10Bv0C0jlKlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(5)"
      ],
      "metadata": {
        "id": "mb5EGfK1lbgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not cap.isOpened():\n",
        "    print(\"Error: Camera not opened.\")\n",
        "else:\n",
        "    # Read a frame from the camera\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Check if the frame reading was successful\n",
        "    if not ret:\n",
        "        print(\"Error: Frame not read properly.\")\n",
        "    else:\n",
        "       ret, frame = cap.read()\n",
        "       gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "       faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "       for (x,y,w,h) in faces:\n",
        "         roi_gray = gray[y:y+h, x:x+w]\n",
        "         roi_color = frame[y:y+h, x:x+w]\n",
        "         eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "         for (ex,ey,ew,eh) in eyes:\n",
        "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "\n",
        "       for (x,y,w,h) in faces:\n",
        "          roi_gray = gray[y:y+h, x:x+w]\n",
        "          roi_color = frame[y:y+h, x:x+w]\n",
        "          eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "          for (ex,ey,ew,eh) in eyes:\n",
        "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
        "            eye_roi_gray = roi_gray[ey:ey+eh, ex:ex+ew]\n",
        "            eye_roi_color = roi_color[ey:ey+eh, ex:ex+ew]\n",
        "            _, eye_thresh = cv2.threshold(eye_roi_gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
        "            contours, _ = cv2.findContours(eye_thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            if len(contours) > 0:\n",
        "               pupil = max(contours, key=cv2.contourArea)\n",
        "               x1, y1, w1, h1 = cv2.boundingRect(pupil)\n",
        "               center = (int(x1 + w1/2), int(y1 + h1/2))\n",
        "               cv2.circle(eye_roi_color, center, 3, (255, 0, 0),-1)\n",
        "\n",
        "\n",
        "       cv2.imshow('Eye Tracking', frame)\n",
        "       while cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "              break\n",
        "\n",
        "    # Release the camera capture\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l7Arwg0ld6q",
        "outputId": "1aa7973f-c58a-4b7b-d247-f70dc03bb5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Camera not opened.\n"
          ]
        }
      ]
    }
  ]
}